{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import tensorflow as tf\n",
    "import imageio\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes it so any changes in pymedphys is automatically\n",
    "# propagated into the notebook without needing a kernel reset.\n",
    "from IPython.lib.deepreload import reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymedphys._experimental.autosegmentation import unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet.unet(grid_size=64, output_channels=4)  # background, patient, brain, eyes\n",
    "# tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = [\n",
    "    str(path) for path in pathlib.Path('data').glob('**/*_image.png')\n",
    "]\n",
    "np.random.shuffle(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_paths = [\n",
    "    f\"{image_path.split('_')[0]}_mask.png\"\n",
    "    for image_path in image_paths\n",
    "]\n",
    "# mask_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normalise_mask(png_mask):\n",
    "    normalised_mask = np.round(png_mask / 255).astype(bool)  # It would be nice if this wasn't needed\n",
    "    categorical_mask = np.zeros_like(normalised_mask[:,:,0]).astype(np.uint8)  # 0 -> background\n",
    "    categorical_mask[normalised_mask[:,:,2]] = 1  # patient\n",
    "    categorical_mask[normalised_mask[:,:,1]] = 2  # brain\n",
    "    categorical_mask[normalised_mask[:,:,0]] = 3  # eyes\n",
    "    \n",
    "    return categorical_mask[:,:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "png_mask = imageio.imread(mask_paths[0])\n",
    "categorical_mask = _normalise_mask(png_mask)\n",
    "plt.imshow(png_mask)\n",
    "plt.show()\n",
    "plt.imshow(categorical_mask)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normalise_image(png_image):\n",
    "    normalised_image = png_image[:,:,None] / 255\n",
    "    return normalised_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_array = _normalise_image(imageio.imread(image_paths[0]))\n",
    "plt.imshow(input_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_arrays = []\n",
    "output_arrays = []\n",
    "for image_path, mask_path in zip(image_paths, mask_paths):\n",
    "    input_arrays.append(_normalise_image(imageio.imread(image_path)))\n",
    "    output_arrays.append(_normalise_mask(imageio.imread(mask_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((input_arrays, output_arrays))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "SHUFFLE_BUFFER_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history = model.fit(\n",
    "    dataset, epochs=1,\n",
    "    steps_per_epoch=20,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymedphys",
   "language": "python",
   "name": "pymedphys"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
